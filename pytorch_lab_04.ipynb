{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNI02NlqjR5o3bttbXYY5BN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlaywls/ML-DL/blob/main/pytorch_lab_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lab 03"
      ],
      "metadata": {
        "id": "vrwfjc3JWR_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "Z99YKLRNXS58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF31a6Vm8_6C",
        "outputId": "fef2d265-f9c7-4c6f-8ed4-800b0f618392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "0l3YGPSkXQh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=torch.FloatTensor([[1],[2],[3]])\n",
        "y_train=torch.FloatTensor([[1],[2],[3]])\n",
        "#모델 초기화\n",
        "w=torch.zeros(1)\n",
        "#learning rate설정\n",
        "lr=0.1\n",
        "nb_epochs=10\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=x_train*w\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "  gradient=torch.sum((w*x_train-y_train)*x_train)\n",
        "  print('Epoch{:4d}/{} W:{:.3f},Cost:{:.6f}'.format(epoch,nb_epochs,w.item(),cost.item()))\n",
        "  w-=lr*gradient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk4pyz4v9F9p",
        "outputId": "f15d0753-3587-4cbb-9be4-4d2b6b7f6faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0/10 W:0.000,Cost:4.666667\n",
            "Epoch   1/10 W:1.400,Cost:0.746666\n",
            "Epoch   2/10 W:0.840,Cost:0.119467\n",
            "Epoch   3/10 W:1.064,Cost:0.019115\n",
            "Epoch   4/10 W:0.974,Cost:0.003058\n",
            "Epoch   5/10 W:1.010,Cost:0.000489\n",
            "Epoch   6/10 W:0.996,Cost:0.000078\n",
            "Epoch   7/10 W:1.002,Cost:0.000013\n",
            "Epoch   8/10 W:0.999,Cost:0.000002\n",
            "Epoch   9/10 W:1.000,Cost:0.000000\n",
            "Epoch  10/10 W:1.000,Cost:0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lab 03 -optimizer"
      ],
      "metadata": {
        "id": "9dGkQ_GNWfaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#모델 초기화\n",
        "w=torch.zeros(1,requires_grad=True)\n",
        "optimizer=optim.SGD([w],lr=0.15)\n",
        "\n",
        "#learning rate설정\n",
        "lr=0.1\n",
        "nb_epochs=10\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=x_train*w\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "  \n",
        "  print('Epoch{:4d}/{} W:{:.3f},Cost:{:.6f}'.format(epoch,nb_epochs,w.item(),cost.item()))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVoWgnrDJFY1",
        "outputId": "9d66bf2e-d321-49df-97dd-307e8bad9332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0/10 W:0.000,Cost:4.666667\n",
            "Epoch   1/10 W:1.400,Cost:0.746667\n",
            "Epoch   2/10 W:0.840,Cost:0.119467\n",
            "Epoch   3/10 W:1.064,Cost:0.019115\n",
            "Epoch   4/10 W:0.974,Cost:0.003058\n",
            "Epoch   5/10 W:1.010,Cost:0.000489\n",
            "Epoch   6/10 W:0.996,Cost:0.000078\n",
            "Epoch   7/10 W:1.002,Cost:0.000013\n",
            "Epoch   8/10 W:0.999,Cost:0.000002\n",
            "Epoch   9/10 W:1.000,Cost:0.000000\n",
            "Epoch  10/10 W:1.000,Cost:0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lab 04\n",
        "multivariate Linear Regression\n",
        "복수의 정보로부터 하나의 값을 추출함."
      ],
      "metadata": {
        "id": "TzswS9sFWi7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터\n",
        "x1_train=torch.FloatTensor([[73],[93],[89],[96],[73]])\n",
        "x2_train=torch.FloatTensor([[80],[88],[91],[98],[66]])\n",
        "x3_train=torch.FloatTensor([[75],[93],[90],[100],[70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
        "\n",
        "#모델 초기화\n",
        "w1=torch.zeros(1,requires_grad=True)\n",
        "w2=torch.zeros(1,requires_grad=True)\n",
        "w3=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)\n",
        "\n",
        "#optimizer설정\n",
        "optimizer=optim.SGD([w1,w2,w3,b],lr=1e-5)\n",
        "\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=x1_train*w1+x2_train*w2+x3_train*w3+b\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, w1.item(), w3.item(), w3.item(), b.item(), cost.item()\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slQ3WsdjYbhE",
        "outputId": "6a2d083d-5407-427a-9bea-ee48fe5b0875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.294 w2: 0.297 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch  100/1000 w1: 0.674 w2: 0.676 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch  200/1000 w1: 0.679 w2: 0.677 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch  300/1000 w1: 0.684 w2: 0.677 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch  400/1000 w1: 0.689 w2: 0.678 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch  500/1000 w1: 0.694 w2: 0.678 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch  600/1000 w1: 0.699 w2: 0.679 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch  700/1000 w1: 0.704 w2: 0.679 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch  800/1000 w1: 0.709 w2: 0.679 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch  900/1000 w1: 0.713 w2: 0.680 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch 1000/1000 w1: 0.718 w2: 0.680 w3: 0.680 b: 0.009 Cost: 1.079390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=torch.FloatTensor([[73,80,76],\n",
        "                          [93,88,93],\n",
        "                          [89,91,90],\n",
        "                          [96,98,100],\n",
        "                          [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
        "\n",
        "#모델 초기화\n",
        "w=torch.zeros((3,1),requires_grad=True)  \n",
        "b=torch.zeros(1,requires_grad=True)   #입력: 3, 출력: 1\n",
        "\n",
        "#optimizer 설정\n",
        "optimizer=optim.SGD([w,b],lr=1e-5)\n",
        "\n",
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=x_train.matmul(w)+b\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        " #100번 맏 로그 출력\n",
        "  print('Epoch{:4d}/{} hypothesis:{} ,Cost:{:.6f}'.format(epoch,nb_epochs,hypothesis.squeeze().detach(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmJgQDBfTGkK",
        "outputId": "1ba9f96d-df12-438d-b311-ed056e9b4577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0/20 hypothesis:tensor([0., 0., 0., 0., 0.]) ,Cost:29661.800781\n",
            "Epoch   1/20 hypothesis:tensor([67.6014, 80.8962, 79.7070, 86.8002, 61.7031]) ,Cost:9278.322266\n",
            "Epoch   2/20 hypothesis:tensor([105.4072, 126.1375, 124.2830, 135.3430,  96.2106]) ,Cost:2903.203125\n",
            "Epoch   3/20 hypothesis:tensor([126.5498, 151.4388, 149.2120, 162.4904, 115.5091]) ,Cost:909.326294\n",
            "Epoch   4/20 hypothesis:tensor([138.3735, 165.5886, 163.1534, 177.6726, 126.3020]) ,Cost:285.722748\n",
            "Epoch   5/20 hypothesis:tensor([144.9857, 173.5020, 170.9501, 186.1631, 132.3381]) ,Cost:90.684326\n",
            "Epoch   6/20 hypothesis:tensor([148.6833, 177.9278, 175.3103, 190.9113, 135.7140]) ,Cost:29.683743\n",
            "Epoch   7/20 hypothesis:tensor([150.7510, 180.4030, 177.7486, 193.5667, 137.6022]) ,Cost:10.604494\n",
            "Epoch   8/20 hypothesis:tensor([151.9072, 181.7874, 179.1122, 195.0517, 138.6584]) ,Cost:4.636605\n",
            "Epoch   9/20 hypothesis:tensor([152.5535, 182.5618, 179.8747, 195.8821, 139.2492]) ,Cost:2.769466\n",
            "Epoch  10/20 hypothesis:tensor([152.9148, 182.9951, 180.3011, 196.3465, 139.5799]) ,Cost:2.184816\n",
            "Epoch  11/20 hypothesis:tensor([153.1166, 183.2375, 180.5395, 196.6061, 139.7650]) ,Cost:2.001340\n",
            "Epoch  12/20 hypothesis:tensor([153.2292, 183.3732, 180.6727, 196.7512, 139.8688]) ,Cost:1.943285\n",
            "Epoch  13/20 hypothesis:tensor([153.2920, 183.4493, 180.7472, 196.8323, 139.9270]) ,Cost:1.924466\n",
            "Epoch  14/20 hypothesis:tensor([153.3269, 183.4920, 180.7888, 196.8776, 139.9598]) ,Cost:1.917930\n",
            "Epoch  15/20 hypothesis:tensor([153.3461, 183.5160, 180.8119, 196.9029, 139.9783]) ,Cost:1.915228\n",
            "Epoch  16/20 hypothesis:tensor([153.3567, 183.5296, 180.8248, 196.9170, 139.9889]) ,Cost:1.913720\n",
            "Epoch  17/20 hypothesis:tensor([153.3624, 183.5374, 180.8320, 196.9248, 139.9950]) ,Cost:1.912590\n",
            "Epoch  18/20 hypothesis:tensor([153.3654, 183.5418, 180.8359, 196.9291, 139.9986]) ,Cost:1.911598\n",
            "Epoch  19/20 hypothesis:tensor([153.3668, 183.5445, 180.8380, 196.9314, 140.0009]) ,Cost:1.910624\n",
            "Epoch  20/20 hypothesis:tensor([153.3674, 183.5461, 180.8392, 196.9327, 140.0023]) ,Cost:1.909670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nn.Module 상속해서 모델 생성"
      ],
      "metadata": {
        "id": "DTIVBq_GW693"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "xjXG-HlZbHbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "sJ03QNA4X7_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x_train=torch.FloatTensor([[73,80,76],\n",
        "                          [93,88,93],\n",
        "                          [89,91,90],\n",
        "                          [96,98,100],\n",
        "                          [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
        "\n",
        "model=MultivariateLinearRegressionModel()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=model(x_train)\n",
        "  \n",
        "  cost=F.mse_loss(hypothesis, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch{:4d}/{} hypothesis:{} ,Cost:{:.6f}'.format(epoch,nb_epochs,hypothesis.squeeze().detach(),cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9NGN3nXW3Xh",
        "outputId": "21b6a689-2cec-4684-8dec-3ab0dccbc5cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0/20 hypothesis:tensor([ 77.4175,  95.3516,  92.5424, 101.0145,  73.1233]) ,Cost:7002.890625\n",
            "Epoch   1/20 hypothesis:tensor([110.2649, 134.6588, 131.2718, 143.1904, 103.1045]) ,Cost:2190.439941\n",
            "Epoch   2/20 hypothesis:tensor([128.6347, 156.6413, 152.9312, 166.7773, 119.8715]) ,Cost:685.302185\n",
            "Epoch   3/20 hypothesis:tensor([138.9079, 168.9350, 165.0441, 179.9681, 129.2485]) ,Cost:214.556808\n",
            "Epoch   4/20 hypothesis:tensor([144.6532, 175.8103, 171.8183, 187.3451, 134.4927]) ,Cost:67.326950\n",
            "Epoch   5/20 hypothesis:tensor([147.8661, 179.6553, 175.6067, 191.4706, 137.4255]) ,Cost:21.279461\n",
            "Epoch   6/20 hypothesis:tensor([149.6629, 181.8057, 177.7253, 193.7778, 139.0657]) ,Cost:6.877536\n",
            "Epoch   7/20 hypothesis:tensor([150.6676, 183.0084, 178.9101, 195.0681, 139.9831]) ,Cost:2.373167\n",
            "Epoch   8/20 hypothesis:tensor([151.2295, 183.6810, 179.5727, 195.7897, 140.4962]) ,Cost:0.964309\n",
            "Epoch   9/20 hypothesis:tensor([151.5437, 184.0572, 179.9433, 196.1931, 140.7832]) ,Cost:0.523630\n",
            "Epoch  10/20 hypothesis:tensor([151.7193, 184.2677, 180.1505, 196.4188, 140.9438]) ,Cost:0.385744\n",
            "Epoch  11/20 hypothesis:tensor([151.8175, 184.3854, 180.2663, 196.5450, 141.0336]) ,Cost:0.342574\n",
            "Epoch  12/20 hypothesis:tensor([151.8723, 184.4512, 180.3311, 196.6155, 141.0840]) ,Cost:0.329013\n",
            "Epoch  13/20 hypothesis:tensor([151.9029, 184.4881, 180.3673, 196.6550, 141.1122]) ,Cost:0.324713\n",
            "Epoch  14/20 hypothesis:tensor([151.9200, 184.5088, 180.3876, 196.6770, 141.1280]) ,Cost:0.323311\n",
            "Epoch  15/20 hypothesis:tensor([151.9294, 184.5204, 180.3989, 196.6893, 141.1369]) ,Cost:0.322817\n",
            "Epoch  16/20 hypothesis:tensor([151.9347, 184.5270, 180.4052, 196.6961, 141.1420]) ,Cost:0.322599\n",
            "Epoch  17/20 hypothesis:tensor([151.9375, 184.5306, 180.4087, 196.7000, 141.1449]) ,Cost:0.322478\n",
            "Epoch  18/20 hypothesis:tensor([151.9391, 184.5328, 180.4106, 196.7021, 141.1465]) ,Cost:0.322379\n",
            "Epoch  19/20 hypothesis:tensor([151.9399, 184.5340, 180.4117, 196.7032, 141.1475]) ,Cost:0.322301\n",
            "Epoch  20/20 hypothesis:tensor([151.9402, 184.5347, 180.4123, 196.7039, 141.1482]) ,Cost:0.322220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lab 04-2\n",
        "\n",
        "복잡한 머신러닝 모델을 학습하려면 많은 양의 데이터가 필요한데 \n",
        "엄청난 양의 데이타를 한번에 학습시키는 것은 하드웨어적으로 불가능하다.\n",
        "\n",
        "따라서 전체 데이터를 균일하게 나눠서 학습한다.\n",
        "\n",
        "\n",
        "이것이 Minibatch Gradient Descent이다."
      ],
      "metadata": {
        "id": "KGeJOjO9a81P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  \n",
        "  def _init_(self):\n",
        "    self.x_data=[[73,80,76],\n",
        "                          [93,88,93],\n",
        "                          [89,91,90],\n",
        "                          [96,98,100],\n",
        "                          [73,66,70]]\n",
        "    self.y_data=[[152],[185],[180],[196],[142]]\n",
        "  def _len_(self):\n",
        "      return len(self.x_data)\n",
        "  def _getitem_(self,idx):\n",
        "    x=torch.FloatTensor(self.x_data[idx])\n",
        "    y=torch.FloatRemsor(self.y_data[idx])\n",
        "    return x,y\n",
        "\n",
        "dataset=CustomDataset()\n",
        "\n",
        "\n",
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  hypothesis=x_train.matmul(w)+b\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch{:4d}/{} hypothesis:{} ,Cost:{:.6f}'.format(epoch,nb_epochs,hypothesis.squeeze().detach(),cost.item()))"
      ],
      "metadata": {
        "id": "0p0EaWBadEHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e871f6e-dd16-467a-f0cb-8f5ecca958ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0/20 hypothesis:tensor([153.3675, 183.5472, 180.8397, 196.9333, 140.0034]) ,Cost:1.908715\n",
            "Epoch   1/20 hypothesis:tensor([153.3674, 183.5480, 180.8400, 196.9337, 140.0042]) ,Cost:1.907764\n",
            "Epoch   2/20 hypothesis:tensor([153.3671, 183.5485, 180.8400, 196.9338, 140.0048]) ,Cost:1.906822\n",
            "Epoch   3/20 hypothesis:tensor([153.3667, 183.5490, 180.8400, 196.9338, 140.0054]) ,Cost:1.905869\n",
            "Epoch   4/20 hypothesis:tensor([153.3662, 183.5494, 180.8399, 196.9337, 140.0059]) ,Cost:1.904923\n",
            "Epoch   5/20 hypothesis:tensor([153.3658, 183.5498, 180.8398, 196.9336, 140.0064]) ,Cost:1.903969\n",
            "Epoch   6/20 hypothesis:tensor([153.3653, 183.5502, 180.8397, 196.9335, 140.0069]) ,Cost:1.903016\n",
            "Epoch   7/20 hypothesis:tensor([153.3648, 183.5505, 180.8396, 196.9334, 140.0074]) ,Cost:1.902055\n",
            "Epoch   8/20 hypothesis:tensor([153.3643, 183.5509, 180.8394, 196.9333, 140.0078]) ,Cost:1.901106\n",
            "Epoch   9/20 hypothesis:tensor([153.3638, 183.5512, 180.8393, 196.9331, 140.0083]) ,Cost:1.900166\n",
            "Epoch  10/20 hypothesis:tensor([153.3633, 183.5516, 180.8391, 196.9330, 140.0088]) ,Cost:1.899245\n",
            "Epoch  11/20 hypothesis:tensor([153.3628, 183.5519, 180.8390, 196.9329, 140.0093]) ,Cost:1.898279\n",
            "Epoch  12/20 hypothesis:tensor([153.3623, 183.5523, 180.8388, 196.9328, 140.0097]) ,Cost:1.897334\n",
            "Epoch  13/20 hypothesis:tensor([153.3618, 183.5526, 180.8387, 196.9326, 140.0102]) ,Cost:1.896386\n",
            "Epoch  14/20 hypothesis:tensor([153.3613, 183.5530, 180.8385, 196.9325, 140.0107]) ,Cost:1.895450\n",
            "Epoch  15/20 hypothesis:tensor([153.3609, 183.5533, 180.8384, 196.9324, 140.0111]) ,Cost:1.894517\n",
            "Epoch  16/20 hypothesis:tensor([153.3604, 183.5536, 180.8382, 196.9322, 140.0116]) ,Cost:1.893557\n",
            "Epoch  17/20 hypothesis:tensor([153.3599, 183.5540, 180.8381, 196.9321, 140.0121]) ,Cost:1.892602\n",
            "Epoch  18/20 hypothesis:tensor([153.3594, 183.5544, 180.8379, 196.9320, 140.0126]) ,Cost:1.891677\n",
            "Epoch  19/20 hypothesis:tensor([153.3589, 183.5547, 180.8378, 196.9318, 140.0131]) ,Cost:1.890720\n",
            "Epoch  20/20 hypothesis:tensor([153.3584, 183.5550, 180.8376, 196.9317, 140.0135]) ,Cost:1.889787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DAscMajxh39q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}